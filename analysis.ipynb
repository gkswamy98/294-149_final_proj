{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_set = np.load(\"./results/test_images.npy\")\n",
    "labels = np.load(\"./results/test_labels.npy\")\n",
    "num_test = len(labels)\n",
    "results = dict()\n",
    "models = [\"AutoEncoder\", \"Convolutional0\", \"Convolutional3\", \"FullyConnected0\", \"FullyConnected2\", \"VAE\"]\n",
    "treatments = [\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"evens\", \"odds\"]\n",
    "for model in models:\n",
    "    for treatment in treatments:\n",
    "        for i in range(5):\n",
    "            results[(model, treatment, i)] = np.load(\"./results/{0}_{1}_{2}.npy\".format(model, treatment, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Performance\n",
    "We take digit with the highest classifier probability as our prediction and use that to compute accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "performance = dict()\n",
    "for model in models:\n",
    "    for treatment in treatments:\n",
    "        avg = 0\n",
    "        for i in range(5):\n",
    "            preds = [np.argmax(softmax(x)) for x in results[(model, treatment, i)]]\n",
    "            acc = np.sum(preds == labels) / num_test\n",
    "            avg += acc\n",
    "        avg /= 5\n",
    "        performance[(model, treatment)] = avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = {\"one\": 1, \"two\": 2, \"three\": 3, \"four\": 4, \"five\": 5, \"six\": 6, \"seven\": 7, \"eight\": 8, \"nine\": 9}\n",
    "new_performance = dict()\n",
    "for model in models:\n",
    "    for treatment in t:\n",
    "        avg = 0\n",
    "        for i in range(5):\n",
    "            preds = [softmax(x) for x in results[(model, treatment, i)]]\n",
    "            n = 0.\n",
    "            d = 0.\n",
    "            for j in range(len(labels)):\n",
    "                if labels[j] == t[treatment]:\n",
    "                    d += 1.\n",
    "                    n += np.max(preds[j])\n",
    "            acc = n / d\n",
    "            avg += acc\n",
    "        avg /= 5\n",
    "        new_performance[(model, treatment)] = avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discritizing Data\n",
    "We discretize all data to make estimation more tractable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_x = [0.1 * x for x in range(11)]\n",
    "X = np.vstack([np.digitize(img.reshape(-1), bins_x) for img in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bins_y = [10 * x for x in range(-5, 5)]\n",
    "Y_dict = dict()\n",
    "for model in models:\n",
    "    for treatment in treatments:\n",
    "        for i in range(5):\n",
    "            Y_dict[(model, treatment, i)] = np.digitize(results[(model, treatment, i)], bins_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Mutual Information\n",
    "This section can take quite a bit to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mutual_info_score\n",
    "\n",
    "# https://stackoverflow.com/questions/20491028/optimal-way-to-compute-pairwise-mutual-information-using-numpy\n",
    "def calc_MI(x, y, bins):\n",
    "    c_xy = np.histogram2d(x, y, bins)[0]\n",
    "    mi = mutual_info_score(None, None, contingency=c_xy)\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [01:16<12:47, 76.76s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [02:31<11:22, 75.88s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [03:49<10:12, 76.61s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [05:12<09:06, 78.04s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [06:33<07:51, 78.60s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [07:45<06:27, 77.51s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [08:57<05:07, 76.84s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [10:11<03:49, 76.47s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [11:28<02:32, 76.49s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [12:44<01:16, 76.42s/it]\u001b[A\n",
      "100%|██████████| 11/11 [14:40<00:00, 80.01s/it]\u001b[A\n",
      " 17%|█▋        | 1/6 [14:40<1:13:20, 880.07s/it]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [01:24<14:03, 84.37s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [02:50<12:45, 85.06s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [04:09<11:04, 83.00s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [05:03<08:51, 75.94s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [05:59<07:11, 71.89s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [06:44<05:36, 67.38s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [07:33<04:18, 64.73s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [08:18<03:06, 62.29s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [09:03<02:00, 60.40s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [09:49<00:58, 58.96s/it]\u001b[A\n",
      "100%|██████████| 11/11 [10:36<00:00, 57.89s/it]\u001b[A\n",
      " 33%|███▎      | 2/6 [25:16<50:33, 758.46s/it]  \n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [00:51<08:37, 51.79s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [01:49<08:12, 54.69s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [02:38<07:02, 52.85s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [03:25<06:00, 51.47s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [04:15<05:06, 51.09s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [05:13<04:21, 52.31s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [06:06<03:29, 52.42s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [06:59<02:37, 52.41s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [07:52<01:44, 52.47s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [08:39<00:51, 51.90s/it]\u001b[A\n",
      "100%|██████████| 11/11 [09:39<00:00, 52.71s/it]\u001b[A\n",
      " 50%|█████     | 3/6 [34:56<34:56, 698.90s/it]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [00:48<08:03, 48.31s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [01:32<06:54, 46.08s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [02:12<05:53, 44.19s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [02:53<05:03, 43.34s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [03:33<04:16, 42.72s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [04:15<03:32, 42.56s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [04:55<02:48, 42.23s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [05:33<02:05, 41.73s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [06:14<01:23, 41.56s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [06:54<00:41, 41.49s/it]\u001b[A\n",
      "100%|██████████| 11/11 [07:35<00:00, 41.44s/it]\u001b[A\n",
      " 67%|██████▋   | 4/6 [42:32<21:16, 638.12s/it]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [00:41<06:55, 41.55s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [01:18<05:54, 39.37s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [01:57<05:13, 39.24s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [02:38<04:37, 39.59s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [03:19<03:58, 39.81s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [03:57<03:18, 39.61s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [04:37<02:38, 39.71s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [05:19<01:59, 39.89s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [05:58<01:19, 39.86s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [06:40<00:40, 40.03s/it]\u001b[A\n",
      "100%|██████████| 11/11 [07:21<00:00, 40.13s/it]\u001b[A\n",
      " 83%|████████▎ | 5/6 [49:53<09:58, 598.79s/it]\n",
      "  0%|          | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "  9%|▉         | 1/11 [00:40<06:43, 40.38s/it]\u001b[A\n",
      " 18%|█▊        | 2/11 [01:20<06:01, 40.16s/it]\u001b[A\n",
      " 27%|██▋       | 3/11 [01:56<05:11, 38.91s/it]\u001b[A\n",
      " 36%|███▋      | 4/11 [02:33<04:28, 38.33s/it]\u001b[A\n",
      " 45%|████▌     | 5/11 [03:11<03:49, 38.28s/it]\u001b[A\n",
      " 55%|█████▍    | 6/11 [03:50<03:12, 38.46s/it]\u001b[A\n",
      " 64%|██████▎   | 7/11 [04:28<02:33, 38.35s/it]\u001b[A\n",
      " 73%|███████▎  | 8/11 [05:08<01:55, 38.54s/it]\u001b[A\n",
      " 82%|████████▏ | 9/11 [05:53<01:18, 39.27s/it]\u001b[A\n",
      " 91%|█████████ | 10/11 [06:43<00:40, 40.35s/it]\u001b[A\n",
      "100%|██████████| 11/11 [07:30<00:00, 40.99s/it]\u001b[A\n",
      "100%|██████████| 6/6 [57:24<00:00, 574.14s/it]\n"
     ]
    }
   ],
   "source": [
    "med_mut_infos = dict()\n",
    "max_mut_infos = dict()\n",
    "min_mut_infos = dict()\n",
    "mean_mut_infos = dict()\n",
    "for model in tqdm(models):\n",
    "    for treatment in tqdm(treatments):\n",
    "        model_mut_infos = []\n",
    "        for pixel in range(len(X[0])):\n",
    "            pixel_vals = X[:, pixel].reshape(-1)\n",
    "            for i in range(5):\n",
    "                model_vals = Y_dict[(model, treatment, i)]\n",
    "                for j in range(10):\n",
    "                    model_feature_val = model_vals[:, j].reshape(-1)\n",
    "                    model_mut_infos.append(calc_MI(pixel_vals, model_feature_val, 10))\n",
    "        med_mut_infos[(model, treatment)] = np.median(model_mut_infos)\n",
    "        max_mut_infos[(model, treatment)] = np.max(model_mut_infos)\n",
    "        min_mut_infos[(model, treatment)] = np.min(model_mut_infos)\n",
    "        mean_mut_infos[(model, treatment)] = np.mean(model_mut_infos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Correlation\n",
    "We consider treatments with a single digit removed and half the digits removed seperately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "med_mi_x = []\n",
    "max_mi_x = []\n",
    "mean_mi_x = []\n",
    "min_mi_x = []\n",
    "acc_y = []\n",
    "for model in [\"AutoEncoder\", \"VAE\"]:\n",
    "    for treatment in treatments:\n",
    "        if treatment not in (\"evens\", \"odds\"):\n",
    "            med_mi_x.append(med_mut_infos[(model, treatment)])\n",
    "            max_mi_x.append(max_mut_infos[(model, treatment)])\n",
    "            mean_mi_x.append(mean_mut_infos[(model, treatment)])\n",
    "            min_mi_x.append(min_mut_infos[(model, treatment)])\n",
    "            acc_y.append(new_performance[(model, treatment)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(med_mi_x, acc_y, color=\"red\", label=\"med: {0}\".format(np.corrcoef(med_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(med_mi_x), np.poly1d(np.polyfit(med_mi_x, acc_y, 1))(np.unique(med_mi_x)), color=\"red\")\n",
    "ax.scatter(mean_mi_x, acc_y, color=\"green\", label=\"mean: {0}\".format(np.corrcoef(mean_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(mean_mi_x), np.poly1d(np.polyfit(mean_mi_x, acc_y, 1))(np.unique(mean_mi_x)), color=\"green\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MI vs. New Confidence on 9-digit Treatments: Neural Models\")\n",
    "plt.savefig(\"./figs/ird_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulswamy/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(max_mi_x, acc_y, color=\"blue\", label=\"max: {0}\".format(np.corrcoef(max_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(max_mi_x), np.poly1d(np.polyfit(max_mi_x, acc_y, 1))(np.unique(max_mi_x)), color=\"blue\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MI vs. Acc on 9-digit Treatments: AE Models\")\n",
    "plt.savefig(\"./figs/ae_max_9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulswamy/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(min_mi_x, acc_y, color=\"purple\", label=\"min: {0}\".format(np.corrcoef(min_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(min_mi_x), np.poly1d(np.polyfit(min_mi_x, acc_y, 1))(np.unique(min_mi_x)), color=\"purple\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MI vs. Acc on 9-digit Treatments: AE Models\")\n",
    "plt.savefig(\"./figs/ae_min_9.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "med_mi_x = []\n",
    "max_mi_x = []\n",
    "mean_mi_x = []\n",
    "min_mi_x = []\n",
    "acc_y = []\n",
    "for model in (\"AutoEncoder\", \"VAE\"):\n",
    "    for treatment in (\"evens\", \"odds\"):\n",
    "        med_mi_x.append(med_mut_infos[(model, treatment)])\n",
    "        max_mi_x.append(max_mut_infos[(model, treatment)])\n",
    "        mean_mi_x.append(mean_mut_infos[(model, treatment)])\n",
    "        min_mi_x.append(min_mut_infos[(model, treatment)])\n",
    "        acc_y.append(performance[(model, treatment)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulswamy/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(med_mi_x, acc_y, color=\"red\", label=\"med: {0}\".format(np.corrcoef(med_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(med_mi_x), np.poly1d(np.polyfit(med_mi_x, acc_y, 1))(np.unique(med_mi_x)), color=\"red\")\n",
    "ax.scatter(mean_mi_x, acc_y, color=\"green\", label=\"mean: {0}\".format(np.corrcoef(mean_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(mean_mi_x), np.poly1d(np.polyfit(mean_mi_x, acc_y, 1))(np.unique(mean_mi_x)), color=\"green\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MI vs. Acc on 5-digit Treatments: AE Models\")\n",
    "plt.savefig(\"./figs/ae_mid_5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulswamy/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(max_mi_x, acc_y, color=\"blue\", label=\"max: {0}\".format(np.corrcoef(max_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(max_mi_x), np.poly1d(np.polyfit(max_mi_x, acc_y, 1))(np.unique(max_mi_x)), color=\"blue\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MI vs. Acc on 5-digit Treatments: AE Models\")\n",
    "plt.savefig(\"./figs/ae_max_5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokulswamy/anaconda/lib/python3.5/site-packages/matplotlib/pyplot.py:524: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(min_mi_x, acc_y, color=\"purple\", label=\"min: {0}\".format(np.corrcoef(min_mi_x, acc_y)[0, 1]))\n",
    "plt.plot(np.unique(min_mi_x), np.poly1d(np.polyfit(min_mi_x, acc_y, 1))(np.unique(min_mi_x)), color=\"purple\")\n",
    "ax.legend()\n",
    "\n",
    "plt.xlabel(\"Mutual Information\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"MI vs. Acc on 5-digit Treatments: AE Models\")\n",
    "plt.savefig(\"./figs/ae_min_5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Across tasks not trained on\n",
    "# break up into groups"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
